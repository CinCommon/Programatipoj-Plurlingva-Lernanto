# Datasources

- For certain providers(like AWS), terraform provides datasources.
- Datasources pro

Terraform data sources allow you to fetch existing resource attributes from outside your Terraform state. This allows referencing information about resources not managed by Terraform.

- **aws_ami** - Fetch the latest AMI id for a given filter

```hcl
data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*"]
  }

  owners = ["099720109477"] # Canonical
}
```

- **aws_subnet** - Lookup subnet ids by filter 

```hcl
data "aws_subnet" "default" {
  filter {
    name   = "vpc-id"
    values = [aws_vpc.main.id]
  }
}
```

- **aws_vpc** - Get VPC id by tag name

```hcl
data "aws_vpc" "main" {
  tags = {
    Name = "main-vpc"
  }
}
```

- **template_file** - Render template from variables

```hcl
data "template_file" "user_data" {
  template = file("${path.module}/script.sh")

  vars = {
    server_port = 8080
  }
}
```

To use a data source:

1. Declare data block with type and unique name
2. Specify arguments to filter/configure data lookup 
3. Output attributes become available for use

Data sources allow reusable, modular Terraform code by externalizing dependencies.

```terraform
data "aws_ip_ranges" "european_ec2" {
	regions = ["eu-west-1", "eu-central-1"]
	services = ["ec2"]
}
resource "aws_security_group" "from_europe" {
	name = "from_europe"
	ingress {
		from_port = "443"
		to_port = "443"
		protocol = "tcp"
		cidr_blocks = slice(data.aws_ip_ranges.european_ec2.cidr_blocks, 0, 50)
	}
	tags = {
		CreateDate = data.aws_ip_ranges.european_ec2.create_date
		SyncToken = data.aws_ip_ranges.european_ec2.sync_token
	}
}
```

In this demo:
1. It defines a `aws_ip_ranges` data source called `european_ec2`, filtering for only EC2 IP ranges in eu-west-1 and eu-central-1 regions. It allows ingress from EC2 instances in Europe without managing any resources there.
2. The `cidr_blocks` attribute contains the list of CIDR ranges for those regions/services. The source IPs are maintained by Amazon so we don't have to manually update firewall rules.
3. The security group resource `aws_security_group.from_europe` ingresses port 443 from a subset of those IP ranges (first 50). Limiting to first 50 CIDR blocks reduces complexity.
4. It also tags the security group with the `create_date` and `sync_token` metadata from the IP ranges data source. Metadata can be used to monitor when IP list was last updated.

- This data source doesn't actually fetch IPs, just the metadata.
- CIDR blocks are max size /24 so should allow sufficient room for EC2 growth.
- Can also use aws_prefix_list resource for referencing these CIDR sets.

Some additional details on Terraform data sources and their purpose:

- **Decouple resource dependencies** - Data sources allow fetching read-only data without depending on the resource itself being managed by Terraform. This decouples the data from the resource lifecycle.

- **Abstract resource details** - By using data sources, you can query attributes of resources without having to hardcode IDs, ARNs, etc directly in config. Resources can be refactored without breaking configs.

- **Reusability** - Common data queries like getting the latest AMI can be defined once and reused across all modules. DRY principle.

- **Encapsulation** - Complex lookup logic can be encapsulated in a data source. The implementation details are hidden from the user of the data.

- **Abstraction** - Data sources provide a Terraform native API over concepts like "latest AMI". This abstracts away provider APIs.

- **Mocking** - Data sources make infrastructure more testable by allowing stubbing fake data for testing.

- **Built-in redundancy** - Data queries are retried on transient failures, avoiding bugs from API timeouts/throttling.

- **Refresh** - Data can be refreshed separately from resources, so queries stay up to date.

So, data sources provide an abstraction layer for external data dependencies, making Terraform code more reusable, testable and robust. They encapsulate read-only queries cleanly separated from resource management.